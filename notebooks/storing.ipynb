{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pymongo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "from pymongo.errors import BulkWriteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of stations ids that have a prediction dataset. Just copy the path where you have locally stored the folder.\n",
    "onlyfiles=[f for f in listdir('/home/usuario/ADS- Project/predictions') if f.endswith(\"_pred.csv\")]\n",
    "ids=[int(re.sub('_pred.csv','',text)) for text in onlyfiles]\n",
    "ids.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_info(station_id):    \n",
    "    #Reading the useful columns of the historical dataset. Also reading \n",
    "    #chicago_stations for the information about the stations\n",
    "    colnames1 = ['id', 'station_name', 'address', 'latitude', 'longitude']\n",
    "    colnames2 = ['ts','total_docks']\n",
    "\n",
    "    stats = pd.read_csv('chicago_stations.csv', names=colnames1,skiprows=[0])\n",
    "    hist = pd.read_csv('data_output/id{}.csv'.format(station_id),names=colnames2,usecols=[1,3],skiprows=np.arange(0,145))\n",
    "    \n",
    "    stats_id=stats[stats.id==station_id] #info for the given station id\n",
    "    docks=int(hist.total_docks.iloc[-1]) #number of total docks at the time the last historical measure was taken\n",
    "    \n",
    "    \n",
    "    #Creating the dicctionary with all the information about the given station\n",
    "    doc={'station_id': station_id,'station_name':stats_id['station_name'].values[0],'address':stats_id['address'].values[0],\n",
    "         'latitude':stats_id['latitude'].values[0],'longitude':stats_id['longitude'].values[0],\n",
    "         'total_docks':docks}\n",
    "    \n",
    "    #Connecting with mlab. Just check the folder with the credentials.\n",
    "    try:\n",
    "        with open(\"credentials/credentials.txt\", 'r', encoding='utf-8') as f:\n",
    "            [name,pasword,url,dbname]=f.read().splitlines()\n",
    "        conn=pymongo.MongoClient(\"mongodb://{}:{}@{}/{}\".format(name,pasword, url,dbname)) \n",
    "    except pymongo.errors.ConnectionFailure as e:\n",
    "        print (\"Could not connect to MongoDB: %s\" % e) \n",
    "    conn\n",
    "    \n",
    "    #Storing the dicctionary in mlab\n",
    "    db = conn['easyrider2']\n",
    "    collection = db['stations']\n",
    "    collection.insert_one(doc)\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And just run the function defined above with all the stations for which we have predictions\n",
    "for i in ids:\n",
    "    station_info(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames2 = ['ts','available_bikes']\n",
    "#Creating a dataset with all the historical and prediction data, adding station_id\n",
    "i=0\n",
    "for station_id in ids:    \n",
    "    hist = pd.read_csv('data_output/id{}.csv'.format(station_id),names=colnames2,usecols=[1,6],skiprows=np.arange(0,145))\n",
    "    pred = pd.read_csv('predictions/{}_pred.csv'.format(station_id), names=colnames2,usecols=[0,1],skiprows=[0])\n",
    "\n",
    "    #Adding a column for station_id into the datasets\n",
    "    hist['station_id']=station_id\n",
    "    pred['station_id']=station_id\n",
    "    #Sorting the columns to have the same order for both datasets\n",
    "    cols = hist.columns.tolist()\n",
    "    cols = [cols[0],cols[-1],cols[1]]\n",
    "    hist = hist[cols]\n",
    "    cols2= pred.columns.tolist()\n",
    "    cols2= [cols2[0],cols2[-1],cols2[1]]\n",
    "    pred = pred[cols2]\n",
    "    #Merging historical and predicted in one dataframe\n",
    "    frames = [hist,pred]\n",
    "    result = pd.concat(frames)\n",
    "\n",
    "    if i==0:\n",
    "        dataset=result.copy()\n",
    "    else:\n",
    "        dataset=pd.concat([dataset,result])\n",
    "    i+=1\n",
    "\n",
    "ds=dataset.sort_values(by=['ts','station_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary from the dataset\n",
    "dic_ds=ds.to_dict('r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"credentials/credentials.txt\", 'r', encoding='utf-8') as f:\n",
    "        [name,pasword,url,dbname]=f.read().splitlines()\n",
    "    conn=pymongo.MongoClient(\"mongodb://{}:{}@{}/{}\".format(name,pasword, url,dbname)) \n",
    "except pymongo.errors.ConnectionFailure as e:\n",
    "    print (\"Could not connect to MongoDB: %s\" % e) \n",
    "conn\n",
    "\n",
    "#Connecting with mlab\n",
    "db = conn['easyrider2']\n",
    "collection = db['states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    collection.insert_many(dic_ds)\n",
    "except BulkWriteError as bwe:\n",
    "    print(bwe.details)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ts_1'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.create_index([(\"ts\", pymongo.ASCENDING)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
